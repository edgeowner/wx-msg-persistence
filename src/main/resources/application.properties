#项目启动端口,默认8080
# server
server.port=8080
server.servlet.context-path=/wechat/persistence
server.tomcat.uri-encoding=UTF-8
server.tomcat.max-threads=1000
# log
logging.level.root=info
logging.level.org.springframework=info
logging.file.max-history=90
spring.aop.auto=true
spring.aop.proxy-target-class=false


# actuator
spring.boot.admin.client.url=http://127.0.0.1:4111
spring.boot.admin.client.service-base-url = http://127.0.0.1:8082

management.endpoints.web.base-path=/actuator
management.server.port=8088
management.endpoints.mappings.sensitive=false
management.endpoints.web.exposure.include=*
management.endpoint.health.show-details=always
management.endpoints.web.exposure.exclude=env,beans
spring.security.user.name=actuator
spring.security.user.password=actuator
spring.security.user.roles=ACTUATOR_ADMIN
management.endpoint.shutdown.enabled=true

info.app.name=wx-msg-persistence
info.app.description=微信Kafka消息持久化
info.app.version=1.0.0






spring.datasource.url=jdbc:mysql://127.0.0.1:3306/wechat_msg?useUnicode=true&character_set_server=utf8mb4&serverTimezone=Asia/Shanghai&useSSL=true
spring.datasource.username=wechat_msg
spring.datasource.password=wechat_msg
spring.datasource.driverClassName=com.mysql.cj.jdbc.Driver


# Druid数据库连接池配置
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource

## 初始化连接池的连接数量 大小，最小，最大
spring.datasource.druid.initialSize=10
spring.datasource.druid.minIdle=5
spring.datasource.druid.maxActive=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.druid.filters=stat


## 配置获取连接等待超时的时间
spring.datasource.druid.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.druid.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.druid.minEvictableIdleTimeMillis=300000
spring.datasource.druid.validationQuery=SELECT 1 FROM DUAL
spring.datasource.druid.testWhileIdle=true
spring.datasource.druid.testOnBorrow=false
spring.datasource.druid.testOnReturn=false
# 是否缓存preparedStatement，也就是PSCache  官方建议MySQL下建议关闭   个人建议如果想用SQL防火墙 建议打开
spring.datasource.druid.poolPreparedStatements=false
spring.datasource.druid.maxPoolPreparedStatementPerConnectionSize=20




spring.datasource.druid.logAbandoned=true
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.druid.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000


# WebStatFilter配置，说明请参考Druid Wiki，配置_配置WebStatFilter
#是否启用StatFilter默认值true
spring.datasource.druid.web-stat-filter.enabled=true

spring.datasource.druid.web-stat-filter.exclusions=*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*
#session统计功能
spring.datasource.druid.web-stat-filter.session-stat-enable=true
#最大session数
spring.datasource.druid.web-stat-filter.session-stat-max-count=100000

#你可以配置principalSessionName，使得druid能够知道当前的session的用户是谁
spring.datasource.druid.web-stat-filter.principal-session-name=admin
spring.datasource.druid.web-stat-filter.principal-cookie-name=admin
#置profileEnable能够监控单个url调用的sql列表。
spring.datasource.druid.web-stat-filter.profile-enable=true


# StatViewServlet配置，说明请参考Druid Wiki，配置_StatViewServlet配置
#是否启用StatViewServlet默认值true
spring.datasource.druid.stat-view-servlet.enabled=true

# 设置不统计哪些URL
spring.datasource.druid.stat-view-servlet.url-pattern=/druid/*
# 设置监控页面的登录名和密码
spring.datasource.druid.stat-view-servlet.login-username=admin
spring.datasource.druid.stat-view-servlet.login-password=123456

## StatViewServlet配置，说明请参考Druid Wiki，配置_StatViewServlet配置



#禁止手动重置监控数据
spring.datasource.druid.stat-view-servlet.reset-enable=false

spring.datasource.druid.aop-patterns=com.atmatrix.wechat.application.*,com.atmatrix.wechat.infrastructure.dao.*,com.atmatrix.wechat.controller.*


# 配置日志输出
spring.datasource.druid.filter.slf4j.enabled=true
spring.datasource.druid.filter.slf4j.statement-create-after-log-enabled=false
spring.datasource.druid.filter.slf4j.statement-close-after-log-enabled=false
spring.datasource.druid.filter.slf4j.result-set-open-after-log-enabled=false


#加载MyBatis配置文件
# 扫描classpath下mapper目录下的所有.xml文件
mybatis.mapper-locations=classpath:mapper/*.xml    
# 实体类的包路径
mybatis.type-aliases-package=com.atmatrix.wechat.infrastructure.po
# 开启驼峰匹配
mybatis.configuration.map-underscore-to-camel-case=true

# swagger
swagger.enable=true
# kafka spring配置
# 更多配置：org.springframework.boot.autoconfigure.kafka.KafkaProperties
#指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=119.3.44.28:9092,119.3.47.237:9092,119.3.40.178:9092,119.3.42.210:9092
#指定默认topic id
spring.kafka.template.default-topic=
#指定listener 容器中的线程数，用于提高并发量
spring.kafka.listener.concurrency=3

#指定默认消费者group id
spring.kafka.consumer.group-id=wx_msg_7
spring.kafka.consumer.enable-auto-commit=false
#若设置为earliest，那么会从头开始读partition
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer


# 自定义kafka 配置 对应 com.atmatrix.wechat.config.KafkaConfig
#kafka.template.default-topic=sunny_test
#kafka.consumer.bootstrapServers=119.3.44.28:9092,119.3.47.237:9092,119.3.40.178:9092,119.3.42.210:9092
##kafka.consumer.groupId=message_test
#kafka.consumer.enableAutoCommit=false
#kafka.consumer.autoCommitIntervalMs=1000
#kafka.consumer.sessionTimeoutMs=30000
#kafka.consumer.maxPollRecords=100
##earliest,latest
#kafka.consumer.autoOffsetReset=earliest
# 文件上传
spring.servlet.multipart.enabled=true 
spring.servlet.multipart.file-size-threshold=0
spring.servlet.multipart.location=
spring.servlet.multipart.max-file-size=5MB
spring.servlet.multipart.max-request-size=10MB
#设置Tomcat缓冲区最大值
server.tomcat.max-http-header-size=819

